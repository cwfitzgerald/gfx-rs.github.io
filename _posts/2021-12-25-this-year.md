---
layout: post
title: This Year in Wgpu - 2021
---

gfx-rs community's goal is to make graphics programming in Rust easy, fast, and reliable. Our main projects are:

  - [wgpu](https://github.com/gfx-rs/wgpu) is built on top of _wgpu-hal_ and _naga_. It provides safety, accessibility, and portability for graphics applications.
  - [naga](https://github.com/gfx-rs/naga) translates shader programs between languages, including WGSL. It also provides shader validation and transformation, ensuring user code running on the GPU is safe and efficient.

As 2021 comes to an end, let's look back at everything that has been accomplished.

![Fredrik NorÃ©n's terrain with trees](/img/fredriknoren.jpg)

## Wgpu

We moved from gfx-hal to the newly created _wgpu-hal_ and restructured the repository to keep everything together. At the same time, we dropped SPIRV-Cross in favor of _naga_, reaching the pure-rust tech stack. Read more in the [0.10 release post]({% post_url 2021-08-18-release-0.10 %}). Credit goes to [@kvark](https://github.com/kvark).

At the same time, [@cwfitzgerald](https://github.com/cwfitzgerald) has revamped our testing infrastructure with Rust integration tests and example snapshots. On top of that, _wgpu_ has tightly [integrated with Deno]({% post_url 2021-09-16-deno-webgpu %}) (thanks to the effort of Deno team!), opening up the road to testing on a real CTS, which is available in CI now.

One shiny highlight of the year was the WebGL port, which became practically usable. Getting it ready was truly a colaborative effort, kicked off by [@zicklag](https://github.com/zicklag). Today, _wgpu-rs_ examples can be [ran online](https://wgpu.rs/examples-gl/?example=cube) with WebGL.

In terms of correctness and portability, [@Wumpf](https://github.com/Wumpf) landed the titanic work of ensuring all our resources are properly zero-initialized. This has proven to be much more involved than it seems, and now users will get consistent behavior across platforms.

Finally, we just released [version 0.12](https://www.reddit.com/r/rust_gamedev/comments/rjci2n/wgpu012_is_released/) with the fresh and good stuff!

## Naga

Naga grew more backends (HLSL, WGSL) and greatly improved support all around the table. It went from an experimental [prototype in 0.3]({% post_url 2021-02-02-release-0.7 %}) to production, shipping in Firefox Nightly. It proved to be [4x faster]({% post_url 2021-05-09-dota2-msl-compilation %}) than SPIRV-Cross at SPV->MSL translation.

One notable improvement, led by [@JCapucho](https://github.com/JCapucho) with some help from [@jimblandy](https://github.com/jimblandy), is the rewrite of SPIR-V control flow processing. This has been a very problematic and complicated area in past, and now it's mostly solved.

Things have been busy on GLSL frontend as well. It got a completely new parser thanks to [@JCapucho](https://github.com/JCapucho), which made it easier to improve and maintain.

Validation grew to cover all the expressions and types and everything. For some time, it was annoying to see rough validation errors without any reference to the source. But [@ElectronicRU](https://github.com/ElectronicRU) saved the day by making our errors really nice, similar to how WGSL parser errors were made pretty by [@grovesNL](https://github.com/grovesNL) work earlier.

Last but not the least, SPIR-V and MSL backends have been bullet-proofed by [@jimblandy](https://github.com/jimblandy).
This includes guarding against out-of-bounds accesses on arrays, buffers, and textures.

## Future Work

One big project that hasn't landed is the removal of "hubs". This is a purely internal change, but a grand one. It would streamline our policy of locking internal data and allow the whole infrastructure to scale better with more elaborate user workloads. We hope to see it coming in 2022.

Another missing piece is DX11 backend. We know it's much needed, and it was the only regression from the _wgpu-hal_ port. This becomes especially important now as Windows stopped supporting DX12 on Intel Haswell GPUs.

Overall, there's been a lot of good quality contributions, and this list by no means can describe the depth of it. We greatly appreciate all the improvements and would love to shout out about your work at the earliest opportunity. Big thanks for everybody involved!
